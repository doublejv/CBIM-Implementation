{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximização de Influência em Redes Sociais\n",
    "## João Victor Galindo Borges do Rego\n",
    "### 1621146"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a graph for testing\n",
    "### Choose a set test graph of 15 nodes or generate your own randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a random upper triangular matrix dataframe\n",
    "\n",
    "a = np.empty(15)\n",
    "b = np.arange(start=0, stop=15, step=1)\n",
    "ind = np.arange(len(a))\n",
    "np.put(a, ind, b)\n",
    "\n",
    "# randomly generated matrix \n",
    "#   uncomment if you want to generate your own 15 x 15 random matrix\n",
    "# matrixDataframe = pd.DataFrame(np.triu(np.random.choice(4, size=(15, 15), p=[0.8, 0.1, 0.05, 0.05])), columns=a, index=a)\n",
    "\n",
    "# set 15 x 15 matrix\n",
    "#   this was originally generated randomly\n",
    "#   used for thesis\n",
    "matrixDataframe = pd.DataFrame(np.array([[0,0,2,0,0,2,0,0,0,1,0,0,0,0,0],\n",
    "                                         [0,0,1,0,0,0,0,0,0,2,0,0,0,0,0],\n",
    "                                         [0,0,0,1,0,0,0,0,0,2,0,1,0,3,0],\n",
    "                                         [0,0,0,0,1,0,0,0,0,0,0,1,0,0,0],\n",
    "                                         [0,0,0,0,0,0,0,0,0,0,1,1,0,0,0],\n",
    "                                         [0,0,0,0,0,0,3,0,2,0,0,1,0,0,0],\n",
    "                                         [0,0,0,0,0,0,2,0,0,0,2,0,1,0,1],\n",
    "                                         [0,0,0,0,0,0,0,0,2,0,0,2,0,0,0],\n",
    "                                         [0,0,0,0,0,0,0,0,0,1,0,0,1,0,0],\n",
    "                                         [0,0,0,0,0,0,0,0,0,0,0,0,0,1,0],\n",
    "                                         [0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],\n",
    "                                         [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "                                         [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "                                         [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "                                         [0,0,0,0,0,0,0,0,0,0,0,0,0,0,1]]))\n",
    "\n",
    "matrixDataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataframe to graph\n",
    "\n",
    "G = nx.from_numpy_matrix(matrixDataframe.values)\n",
    "G.remove_edges_from(nx.selfloop_edges(G))\n",
    "\n",
    "print(G.number_of_nodes(), G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw graph\n",
    "\n",
    "# subax1 = plt.subplot()\n",
    "# nx.draw_kamada_kawai(G, with_labels=True, font_weight='bold')\n",
    "\n",
    "elarge = [(u, v) for (u, v, d) in G.edges(data=True) if d[\"weight\"] > 2]\n",
    "emedium = [(u, v) for (u, v, d) in G.edges(data=True) if d[\"weight\"] > 1 and d[\"weight\"] <= 2]\n",
    "esmall = [(u, v) for (u, v, d) in G.edges(data=True) if d[\"weight\"] <= 1]\n",
    "\n",
    "pos = nx.kamada_kawai_layout(G)  # positions for all nodes - seed for reproducibility\n",
    "\n",
    "# nodes\n",
    "nx.draw_networkx_nodes(G, pos)\n",
    "\n",
    "# edges\n",
    "nx.draw_networkx_edges(G, pos, edgelist=elarge, width= 2, alpha=1, edge_color=\"r\")\n",
    "nx.draw_networkx_edges(G, pos, edgelist=emedium, width= 2, alpha=1, edge_color=\"g\")\n",
    "nx.draw_networkx_edges(G, pos, edgelist=esmall, width= 2, alpha=0.75, edge_color=\"b\")\n",
    "\n",
    "# node labels\n",
    "nx.draw_networkx_labels(G, pos, font_size=12, font_family=\"sans-serif\")\n",
    "# edge weight labels\n",
    "edge_labels = nx.get_edge_attributes(G, \"weight\")\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export graph for better visualization\n",
    "#   only necessary for really big graphs\n",
    "\n",
    "nx.write_graphml(G, './Graph.graphml')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Community Based Influence Maximization\n",
    "### Set your own values for *k* and *δ* below and run all remaining cells\n",
    "### Relevant data printed at the very bottom of this document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CBIM parameters\n",
    "\n",
    "# k\n",
    "seedNodeAmount = 2\n",
    "\n",
    "# δ\n",
    "mergingIndexThreshold = 0.4\n",
    "\n",
    "print(\"k = \" + str(seedNodeAmount))\n",
    "print(\"δ = \" + str(mergingIndexThreshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# community based influence maximization algorithm\n",
    "# Phase 1 - Initial communities detection\n",
    "\n",
    "import copy\n",
    "import random\n",
    "\n",
    "# 1. Initialize the variables 'NS' and 'CSinit'\n",
    "\n",
    "NS = list(G.nodes)\n",
    "CSinit = []\n",
    "\n",
    "\n",
    "while len(NS) > 0:\n",
    "\n",
    "    # 2. Select the highest degree nodes 'Dv'\n",
    "\n",
    "    degreeList = G.degree(weight=\"weight\")\n",
    "    highestDegree = 0\n",
    "    highestDegreeNodes = []\n",
    "    for node in degreeList:\n",
    "        if node[1] == highestDegree and NS.count(node[0]) > 0:\n",
    "            highestDegreeNodes.append(node)\n",
    "        elif node[1] > highestDegree and NS.count(node[0]) > 0:\n",
    "            highestDegree = node[1]\n",
    "            highestDegreeNodes = []\n",
    "            highestDegreeNodes.append(node)\n",
    "\n",
    "\n",
    "    # 3. Randomly select a node 'v' from 'Dv'\n",
    "\n",
    "    print(\"The highest degree nodes are: \" + str(highestDegreeNodes))\n",
    "    v, _ = random.choice(highestDegreeNodes)\n",
    "    print(\"The chosen highest degree (v) node is: \" + str(v))\n",
    "\n",
    "\n",
    "    # 4. Get the most similar neighbours of 'v' using Dice neighbour similarity\n",
    "\n",
    "    highestDSC = .0\n",
    "    highestDSCNodes = []\n",
    "    for u in G.neighbors(v):\n",
    "        DSC = (2 * len(list(nx.common_neighbors(G, u, v)))) / (len(list(G.neighbors(u))) + len(list(G.neighbors(v))))\n",
    "        if DSC == highestDSC:\n",
    "            highestDSCNodes.append(u)\n",
    "        elif DSC > highestDSC:\n",
    "            highestDSC = DSC\n",
    "            highestDSCNodes = []\n",
    "            highestDSCNodes.append(u)\n",
    "\n",
    "\n",
    "    # 5. Randomly select a neighbour 'sn' from the most similar neighbours list\n",
    "\n",
    "    print(\"The most similar neighbour nodes are: \" + str(highestDSCNodes))\n",
    "    sn = random.choice(highestDSCNodes)\n",
    "    print(\"The chosen neighbour node (sn) is: \" + str(sn))\n",
    "\n",
    "\n",
    "    # 6. IF 'sn' is not in any community THEN\n",
    "\n",
    "    nodeIsPresent = False\n",
    "    for C in CSinit:\n",
    "\n",
    "        # 10. ELSE\n",
    "        # 11. Find the community to which 'sn' belongs to and denote it as 'C'\n",
    "        print(C)\n",
    "        print(C.count(sn))\n",
    "        if C.count(sn) > 0:\n",
    "\n",
    "            # 12. Insert node 'v' into 'C' and remove node 'v' from 'NS'\n",
    "            C.append(v)\n",
    "            NS.remove(v)\n",
    "\n",
    "            nodeIsPresent = True\n",
    "\n",
    "    if not nodeIsPresent:\n",
    "        # 7. Create a new community and assign 'v' and 'sn' to it\n",
    "        community = [v, sn]\n",
    "\n",
    "        # 8. Insert the new community into community structure\n",
    "        CSinit.append(community)\n",
    "\n",
    "        # 9. Remove 'v' and 'sn' from NS\n",
    "        NS.remove(v)\n",
    "        NS.remove(sn)\n",
    "\n",
    "\n",
    "    # 13. Repeat the steps from 2 to 12, until 'NS' = null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initial communities list (CSinit): \" + str(CSinit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2 - Community consolidation\n",
    "# 14. Initialize Final Communities (FC)\n",
    "\n",
    "FC = CSinit.copy()\n",
    "\n",
    "\n",
    "# 15. Calculate community conductance (γi) and community scale (θi) for each community 'C' in CSinit\n",
    "\n",
    "EoutList = np.zeros(len(CSinit))\n",
    "EinList = np.zeros(len(CSinit))\n",
    "conductanceList = np.zeros(len(CSinit))\n",
    "scaleList = np.zeros(len(CSinit))\n",
    "i = 0\n",
    "for C in CSinit:\n",
    "    visitedNodes = []\n",
    "    for node in C:\n",
    "        visitedNodes.append(node)\n",
    "        for neighbor in list(G.neighbors(node)):\n",
    "            if visitedNodes.count(neighbor) == 0:\n",
    "                if C.count(neighbor) == 0:\n",
    "                    EoutList[i] += G[node][neighbor][\"weight\"]\n",
    "                else:\n",
    "                    EinList[i] += G[node][neighbor][\"weight\"]\n",
    "    conductanceList[i] = EoutList[i] / (2 * EinList[i] + EoutList[i])\n",
    "    scaleList[i] = len(C) / len(list(G.nodes))\n",
    "    i += 1\n",
    "\n",
    "print(\"Community conductances: \" + str(conductanceList))\n",
    "print(\"Community scales: \" + str(scaleList))\n",
    "\n",
    "\n",
    "# 16. Calculate the merging index (ψi) for each community in CSinit.\n",
    "\n",
    "mergingIndexList = np.zeros(len(CSinit))\n",
    "i = 0\n",
    "for index in mergingIndexList:\n",
    "    mergingIndexList[i] = conductanceList[i] * scaleList[i]\n",
    "    i += 1\n",
    "\n",
    "print(\"Community merging indexes: \" + str(mergingIndexList))\n",
    "\n",
    "\n",
    "# 17. Select the community with lowest merging index (Cx)\n",
    "\n",
    "lowestMergingIndex = (0, 0)\n",
    "mergingIndexList.sort\n",
    "i = 0\n",
    "for index in mergingIndexList:\n",
    "    if mergingIndexList[i] < lowestMergingIndex[1] or lowestMergingIndex == (0, 0):\n",
    "        lowestMergingIndex= (i, mergingIndexList[i])\n",
    "    i += 1\n",
    "\n",
    "\n",
    "while lowestMergingIndex[1] <= mergingIndexThreshold:\n",
    "    # 17. Select the community with lowest merging index (Cx)\n",
    "\n",
    "    lowestMergingIndex = (0, 0)\n",
    "    mergingIndexList.sort\n",
    "    i = 0\n",
    "    for index in mergingIndexList:\n",
    "        if mergingIndexList[i] < lowestMergingIndex[1] or lowestMergingIndex == (0, 0):\n",
    "            lowestMergingIndex= (i, mergingIndexList[i])\n",
    "        i += 1\n",
    "\n",
    "    print(\"Lowest merging index community: \" + str(lowestMergingIndex[0]))\n",
    "\n",
    "\n",
    "    # 18. Find the most similar community (Cy) to (Cx) and merge the two communites to form a new community (Cn)\n",
    "\n",
    "    similarityList = np.zeros(len(CSinit))\n",
    "    i = 0\n",
    "    for C in FC:\n",
    "        DSCsum = 0\n",
    "        if i != lowestMergingIndex[0]:\n",
    "            for u in CSinit[lowestMergingIndex[0]]:\n",
    "                for v in C:\n",
    "                    DSCsum += (2 * len(list(nx.common_neighbors(G, u, v)))) / (len(list(G.neighbors(u))) + len(list(G.neighbors(v))))\n",
    "            similarityList[i] = DSCsum / len(CSinit[lowestMergingIndex[0]])\n",
    "        i += 1\n",
    "\n",
    "    print(\"Communities similarity to community \" + str(lowestMergingIndex[0]) + \": \" + str(similarityList))\n",
    "\n",
    "    highestSimilarity = (0, 0)\n",
    "    i = 0\n",
    "    for similarity in similarityList:\n",
    "        if similarity > highestSimilarity[1]:\n",
    "            highestSimilarity = (i, similarity)\n",
    "        i += 1\n",
    "\n",
    "    print(\"Most similar community: \" + str(highestSimilarity[0]))\n",
    "\n",
    "    newCommunity = FC[lowestMergingIndex[0]] + FC[highestSimilarity[0]]\n",
    "\n",
    "    print(\"New community: \" + str(newCommunity))\n",
    "\n",
    "\n",
    "    # 19. Calculate the merging index (ψn) for new community (Cn)\n",
    "\n",
    "    Eout = 0\n",
    "    Ein = 0\n",
    "    conductance = 0\n",
    "    scale = len(newCommunity) / len(list(G.nodes))\n",
    "\n",
    "    visitedNodes = []\n",
    "    for node in newCommunity:\n",
    "            visitedNodes.append(node)\n",
    "            for neighbor in list(G.neighbors(node)):\n",
    "                if visitedNodes.count(neighbor) == 0:\n",
    "                    if C.count(neighbor) == 0:\n",
    "                        Eout += G[node][neighbor][\"weight\"]\n",
    "                    else:\n",
    "                        Ein += G[node][neighbor][\"weight\"]\n",
    "\n",
    "    conductance = Eout / (2 * Ein + Eout)\n",
    "\n",
    "    print(\"New community conductance: \" + str(conductance))\n",
    "    print(\"New community scale: \" + str(scale))\n",
    "\n",
    "    mergingIndex = conductance * scale\n",
    "\n",
    "    print(\"New community merging index: \" + str(mergingIndex))\n",
    "\n",
    "\n",
    "    # 20. Replace two communites 'Cx' and 'Cy' with new community 'Cn' in final community set (FC)\n",
    "\n",
    "    FC[lowestMergingIndex[0]] = newCommunity\n",
    "    del FC[highestSimilarity[0]]\n",
    "\n",
    "    print(\"Final Communities list (FC) so far: \" + str(FC))\n",
    "\n",
    "\n",
    "    # 21. Repeat the process from 17 to 20 until 'ψi' > 'δ'\n",
    "\n",
    "    lowestMergingIndex = (0, mergingIndex)\n",
    "\n",
    "\n",
    "print(\"Final Communities list (FC): \" + str(FC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Katz centrality coeficient and seed node selection\n",
    "# 1. Initialize the Seed node set (SN) and Community set (CS)\n",
    "\n",
    "SN = np.zeros(len(FC))\n",
    "CS = FC.copy()\n",
    "\n",
    "\n",
    "# 2. Calculate Katz centrality for each node\n",
    "\n",
    "katzCentralityDict = nx.katz_centrality(G, alpha=0.1, beta=0.01, max_iter=100, weight=\"weight\")\n",
    "katzCentralityList = [(k, v) for k, v in katzCentralityDict.items()]\n",
    "\n",
    "\n",
    "# 3. Sort all the nodes in each community based on Katz Centrality Coeficient in descending order\n",
    "\n",
    "katzCentralityList.sort(key=lambda a: a[1], reverse=True)\n",
    "print(\"Katz Centrality coeficients for every node: \" + str(katzCentralityList))\n",
    "\n",
    "\n",
    "# 4. Calculate required seed nodes from each community in quota based approach\n",
    "\n",
    "quotaList = np.zeros(len(CS))\n",
    "i = 0\n",
    "for C in CS:\n",
    "    quotaList[i] = round(seedNodeAmount * (len(C) / len(list(G.nodes))))\n",
    "    # if quotaList[i] == 0:\n",
    "    #     quotaList[i] = 1\n",
    "    i += 1\n",
    "\n",
    "print(\"Quotas for every community: \" + str(quotaList))\n",
    "quotaListBackup = quotaList.copy()\n",
    "\n",
    "# 5. Select the quota number of highest Katz centrality coeficient nodes as seed nodes from each community (Ci)\n",
    "\n",
    "SN = np.zeros(int(sum(quotaList)))\n",
    "i = 0\n",
    "j = 0\n",
    "for C in CS:\n",
    "    for node in katzCentralityList:\n",
    "        if C.count(node[0]) > 0 and quotaList[i] > 0:\n",
    "            quotaList[i] -= 1\n",
    "            SN[j] = node[0]\n",
    "            j += 1\n",
    "    i += 1\n",
    "\n",
    "print(\"Community Set (CS): \" + str(CS))\n",
    "print(\"Seed Nodes: \" + str(SN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------------------------------\")\n",
    "print(\"Parameters:\") \n",
    "print(\"------------------------------\")\n",
    "print(\"k = \" + str(seedNodeAmount)) \n",
    "print(\"δ = \" + str(mergingIndexThreshold))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"------------------------------\")\n",
    "print(\"Relevant data for this run:\")\n",
    "print(\"------------------------------\")\n",
    "print(\"Initial communities list (CSinit): \" + str(CSinit))\n",
    "print(\"Final Communities list (FC): \" + str(FC))\n",
    "print(\"Quotas for every community: \" + str(quotaListBackup))\n",
    "print(\"Katz Centrality coeficients for every node: \" + str(katzCentralityList))\n",
    "print(\"Seed Nodes: \" + str(SN))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6c1911f47bc64ce98f6452a334b38112aa13752bde8a056fe618aa17c069f992"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
